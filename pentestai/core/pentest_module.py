"""
Stage 1: Pentest Module - Autonomous Vulnerability Discovery

Implements the Pentest Module from the PenHeal paper with 6 agents:
1. Planner - Creates attack plans with counterfactual reasoning
2. Executor - Generates and executes commands  
3. Instructor - Provides RAG-based guidance from knowledge base
4. Summarizer - Condenses command outputs
5. Extractor - Parses vulnerabilities from results
6. Monitor - Tracks progress and handles errors (new)

Architecture based on: arXiv:2407.17788v1 (PenHeal Paper)
"""

import logging
import json
from typing import Optional
from datetime import datetime

from pentestai.models.data import (
    AttackPlanNode,
    ExecutionResult,
    PentestPhase,
    PentestResult,
    TaskStatus,
    Vulnerability,
    VulnerabilitySeverity,
)
from pentestai.knowledge.base import search_knowledge
from pentestai.core.config import PentestAIConfig
from pentestai.llm.client import LLMClient, OpenAIClient, MockLLMClient

logger = logging.getLogger(__name__)


class PlannerAgent:
    """
    Planner Agent - Creates and updates attack plans with counterfactual reasoning.
    
    Key features:
    - Hierarchical task structure (PTT-based)
    - Counterfactual prompting to explore multiple attack paths
    - Dynamic plan updates based on results
    - Real LLM integration for intelligent planning
    """

    def __init__(self, config: PentestAIConfig, llm_client: Optional[LLMClient] = None):
        self.config = config
        self.attack_plan: Optional[AttackPlanNode] = None
        self.vulnerabilities_found: list[str] = []
        
        # Initialize LLM client
        if llm_client:
            self.llm = llm_client
        elif config.openai_api_key:
            self.llm = OpenAIClient(
                api_key=config.openai_api_key,
                model=config.planner_model,
            )
        else:
            logger.warning("No OpenAI API key - using mock LLM client")
            self.llm = MockLLMClient()

    def create_initial_plan(self, target: str) -> AttackPlanNode:
        """
        Create initial attack plan following standard pentest phases.
        
        Args:
            target: Target system IP/hostname
            
        Returns:
            Root attack plan node
        """
        logger.info(f"Creating initial attack plan for target: {target}")
        
        # Create root node
        root = AttackPlanNode(
            id="0",
            phase=PentestPhase.RECONNAISSANCE,
            description="Complete Penetration Test",
            status=TaskStatus.IN_PROGRESS,
            metadata={"target": target}
        )
        
        # Phase 1: Reconnaissance
        recon = AttackPlanNode(
            id="1",
            phase=PentestPhase.RECONNAISSANCE,
            description="Reconnaissance - Information Gathering",
            status=TaskStatus.TODO,
            parent_id="0",
        )
        recon.subtasks = [
            AttackPlanNode(
                id="1.1",
                phase=PentestPhase.RECONNAISSANCE,
                description=f"Port scan target {target}",
                status=TaskStatus.TODO,
                command=f"nmap -sV {target}",
                parent_id="1",
            ),
            AttackPlanNode(
                id="1.2",
                phase=PentestPhase.RECONNAISSANCE,
                description=f"Vulnerability scan target {target}",
                status=TaskStatus.TODO,
                command=f"nmap --script vuln {target}",
                parent_id="1",
            ),
        ]
        
        # Phase 2: Exploitation
        exploit = AttackPlanNode(
            id="2",
            phase=PentestPhase.EXPLOITATION,
            description="Exploitation - Attack vulnerable services",
            status=TaskStatus.TODO,
            parent_id="0",
        )
        
        root.subtasks = [recon, exploit]
        self.attack_plan = root
        
        logger.info("Initial attack plan created with reconnaissance and exploitation phases")
        return root

    def apply_counterfactual_reasoning(self, vulnerabilities: list[str]) -> None:
        """
        Apply counterfactual prompting to explore alternative attack paths.
        
        This is a key innovation from the PenHeal paper: "Assume discovered
        vulnerabilities don't exist - what other vulnerabilities could be present?"
        
        Uses LLM to generate alternative exploration strategies.
        
        Args:
            vulnerabilities: List of already-discovered vulnerability names
        """
        logger.info(f"Applying counterfactual reasoning. Known vulnerabilities: {len(vulnerabilities)}")
        
        self.vulnerabilities_found.extend(vulnerabilities)
        
        if not vulnerabilities or not self.attack_plan:
            return
        
        # Construct counterfactual prompt for LLM
        system_prompt = """You are a penetration testing expert. Your task is to suggest 
        alternative attack vectors when asked to think counterfactually."""
        
        user_prompt = f"""
        We have discovered these vulnerabilities on target {self.config.target}:
        {', '.join(vulnerabilities)}
        
        Apply counterfactual reasoning: Assume these vulnerabilities do NOT exist.
        What other attack vectors, services, or misconfigurations should we explore?
        
        Suggest 2-3 specific reconnaissance or exploitation tasks in this format:
        1. Task description
        2. Specific command to execute
        
        Focus on commonly overlooked attack surfaces.
        """
        
        try:
            response = self.llm.generate(
                prompt=user_prompt,
                system_prompt=system_prompt,
                temperature=0.7,
                max_tokens=500,
            )
            
            # Parse response and add tasks to attack plan
            exploit_node = next((n for n in self.attack_plan.subtasks if n.id == "2"), None)
            if exploit_node:
                # Add counterfactual exploration task
                alt_task = AttackPlanNode(
                    id=f"2.{len(exploit_node.subtasks) + 1}",
                    phase=PentestPhase.EXPLOITATION,
                    description=f"Counterfactual exploration: {response.content[:100]}",
                    status=TaskStatus.TODO,
                    parent_id="2",
                    metadata={
                        "counterfactual": True,
                        "ignoring": vulnerabilities,
                        "llm_suggestion": response.content,
                    }
                )
                exploit_node.subtasks.append(alt_task)
                logger.info("Counterfactual reasoning applied - LLM generated alternative tasks")
        
        except Exception as e:
            logger.warning(f"LLM counterfactual reasoning failed: {e}. Using fallback logic.")
            # Fallback to simple logic
            exploit_node = next((n for n in self.attack_plan.subtasks if n.id == "2"), None)
            if exploit_node:
                alt_task = AttackPlanNode(
                    id=f"2.{len(exploit_node.subtasks) + 1}",
                    phase=PentestPhase.EXPLOITATION,
                    description="Explore alternative attack vectors (counterfactual)",
                    status=TaskStatus.TODO,
                    parent_id="2",
                    metadata={"counterfactual": True, "ignoring": vulnerabilities}
                )
                exploit_node.subtasks.append(alt_task)

    def update_task_status(self, task_id: str, status: TaskStatus, output_summary: str = "") -> None:
        """Update task status and output in the attack plan."""
        def _update_recursive(node: AttackPlanNode) -> bool:
            if node.id == task_id:
                node.status = status
                node.output_summary = output_summary
                return True
            for subtask in node.subtasks:
                if _update_recursive(subtask):
                    return True
            return False
        
        if self.attack_plan:
            if _update_recursive(self.attack_plan):
                logger.info(f"Updated task {task_id} status to {status}")
            else:
                logger.warning(f"Task {task_id} not found in attack plan")

    def get_next_task(self) -> Optional[AttackPlanNode]:
        """Get the next task to execute from the attack plan."""
        def _find_next(node: AttackPlanNode) -> Optional[AttackPlanNode]:
            if node.status == TaskStatus.TODO and node.command:
                return node
            for subtask in node.subtasks:
                result = _find_next(subtask)
                if result:
                    return result
            return None
        
        if self.attack_plan:
            return _find_next(self.attack_plan)
        return None


class ExecutorAgent:
    """
    Executor Agent - Generates and executes penetration testing commands.
    
    Responsibilities:
    - Generate commands based on tasks using LLM
    - Execute commands in simulated/sandboxed environment
    - Format commands for parsing (wrapped in $...$)
    """

    def __init__(self, config: PentestAIConfig, llm_client: Optional[LLMClient] = None):
        self.config = config
        
        # Initialize LLM client
        if llm_client:
            self.llm = llm_client
        elif config.openai_api_key:
            self.llm = OpenAIClient(
                api_key=config.openai_api_key,
                model=config.executor_model,
            )
        else:
            logger.warning("No OpenAI API key - using mock LLM client")
            self.llm = MockLLMClient()

    def execute_task(self, task: AttackPlanNode, guidance: str = "") -> ExecutionResult:
        """
        Execute a penetration testing task.
        
        Args:
            task: Task from attack plan
            guidance: Optional guidance from Instructor
            
        Returns:
            Execution result with output/vulnerabilities
        """
        logger.info(f"Executing task {task.id}: {task.description}")
        
        command = task.command
        
        if self.config.sandbox_mode:
            # SIMULATION MODE - Return symbolic results
            output = self._simulate_execution(command, task.description)
            success = "ERROR" not in output and "FAILED" not in output
        else:
            # REAL MODE - Would execute actual command (NOT RECOMMENDED)
            logger.warning("Real execution mode - this should only be used in controlled sandboxes!")
            output = "REAL_EXECUTION_DISABLED_FOR_SAFETY"
            success = False
        
        # Parse for vulnerabilities
        vulnerabilities_found = self._parse_vulnerabilities(output)
        
        result = ExecutionResult(
            task_id=task.id,
            command=command,
            output=output,
            success=success,
            vulnerabilities_found=vulnerabilities_found,
            timestamp=datetime.now(),
        )
        
        logger.info(f"Task {task.id} completed. Vulnerabilities found: {len(vulnerabilities_found)}")
        return result

    def _simulate_execution(self, command: str, description: str) -> str:
        """
        Simulate command execution with symbolic outputs.
        
        This is SAFE for research - returns symbolic indicators instead of real attacks.
        """
        cmd_lower = command.lower()
        
        # Nmap port scan simulation
        if "nmap" in cmd_lower and "-sv" in cmd_lower:
            return """
            PORT_21_OPEN: FTP (vsFTPd 2.3.4)
            PORT_22_OPEN: SSH (OpenSSH 7.2)
            PORT_80_OPEN: HTTP (Apache 2.4.18)
            PORT_139_OPEN: NetBIOS (Samba 3.X)
            PORT_445_OPEN: SMB (Samba 3.X)
            PORT_6667_OPEN: IRC (UnrealIRCd 3.2.8.1)
            """
        
        # Nmap vulnerability scan simulation
        elif "nmap" in cmd_lower and "vuln" in cmd_lower:
            return """
            VULNERABILITY_DETECTED: CVE-2011-2523 (vsFTPd backdoor)
            VULNERABILITY_DETECTED: CVE-2010-2075 (UnrealIRCd backdoor)
            VULNERABILITY_DETECTED: CVE-2007-2447 (Samba usermap_script)
            SQL_INJECTION_POSSIBLE: Port 80
            """
        
        # Metasploit FTP backdoor simulation
        elif "vsftpd" in cmd_lower or "ftp" in cmd_lower:
            return """
            EXPLOIT_SUCCESSFUL: vsFTPd 2.3.4 backdoor triggered
            SHELL_OBTAINED: Root access established
            VULNERABILITY_CONFIRMED: CVE-2011-2523
            """
        
        # Metasploit IRC backdoor simulation
        elif "unreal" in cmd_lower or ("irc" in cmd_lower and "backdoor" in cmd_lower):
            return """
            EXPLOIT_SUCCESSFUL: UnrealIRCd backdoor triggered
            REVERSE_SHELL_ESTABLISHED: Command execution available
            VULNERABILITY_CONFIRMED: CVE-2010-2075
            """
        
        # Metasploit Samba exploitation simulation
        elif "samba" in cmd_lower or "usermap" in cmd_lower:
            return """
            EXPLOIT_SUCCESSFUL: Samba usermap_script RCE
            ROOT_SHELL_OBTAINED: Full system access
            VULNERABILITY_CONFIRMED: CVE-2007-2447
            """
        
        # SQLMap simulation
        elif "sqlmap" in cmd_lower:
            return """
            SQL_INJECTION_CONFIRMED: Parameter 'id' is vulnerable
            DATABASE_ACCESS_OBTAINED: MySQL database
            SENSITIVE_DATA_EXTRACTED: 5 tables dumped
            """
        
        # Default simulation
        else:
            return f"COMMAND_EXECUTED: {command}\nOUTPUT_SIMULATED: Task completed successfully"

    def _parse_vulnerabilities(self, output: str) -> list[str]:
        """Parse vulnerability indicators from command output."""
        vulnerabilities = []
        
        keywords = [
            "VULNERABILITY_DETECTED",
            "VULNERABILITY_CONFIRMED",
            "CVE-",
            "EXPLOIT_SUCCESSFUL",
            "SQL_INJECTION",
            "BACKDOOR",
        ]
        
        for line in output.split("\n"):
            if any(keyword in line for keyword in keywords):
                vulnerabilities.append(line.strip())
        
        return vulnerabilities


class InstructorAgent:
    """
    Instructor Agent - Provides RAG-based guidance from knowledge base.
    
    Uses the knowledge base to provide context-aware guidance for tasks.
    """

    def __init__(self, config: PentestAIConfig, llm_client: Optional[LLMClient] = None):
        self.config = config
        self.llm = llm_client or MockLLMClient()

    def get_guidance(self, task: AttackPlanNode) -> str:
        """
        Get guidance from knowledge base for a task.
        
        Args:
            task: Task needing guidance
            
        Returns:
            Formatted guidance text
        """
        if not self.config.use_instructor:
            return ""
        
        # Search knowledge base
        query = task.description + " " + task.command
        entries = search_knowledge(query, top_k=2)
        
        if not entries:
            return ""
        
        guidance_parts = ["Guidance from knowledge base:"]
        for i, entry in enumerate(entries, 1):
            guidance_parts.append(f"\n{i}. {entry.title}")
            guidance_parts.append(f"   {entry.content[:300]}...")
        
        return "\n".join(guidance_parts)


class SummarizerAgent:
    """
    Summarizer Agent - Condenses verbose command outputs.
    
    Addresses the context window limitation problem mentioned in the paper.
    """

    def __init__(self, config: PentestAIConfig, llm_client: Optional[LLMClient] = None):
        self.config = config
        self.llm = llm_client or MockLLMClient()

    def summarize(self, output: str, max_length: int = 500) -> str:
        """
        Summarize command output to essential information.
        
        Args:
            output: Raw command output
            max_length: Maximum summary length
            
        Returns:
            Summarized output
        """
        if len(output) <= max_length:
            return output
        
        # Extract key lines (those with uppercase keywords)
        important_lines = []
        for line in output.split("\n"):
            if any(keyword in line.upper() for keyword in [
                "PORT", "OPEN", "VULNERABILITY", "CVE", "EXPLOIT",
                "SUCCESS", "FAILED", "ERROR", "DETECTED", "FOUND"
            ]):
                important_lines.append(line)
        
        summary = "\n".join(important_lines)
        
        if len(summary) > max_length:
            summary = summary[:max_length] + "..."
        
        return summary if summary else output[:max_length] + "..."


class ExtractorAgent:
    """
    Extractor Agent - Parses structured vulnerability data from results.
    
    Converts symbolic/textual results into structured Vulnerability objects.
    """

    def __init__(self, config: PentestAIConfig, llm_client: Optional[LLMClient] = None):
        self.config = config
        self.llm = llm_client or MockLLMClient()

    def extract_vulnerabilities(self, execution_history: list[ExecutionResult]) -> list[Vulnerability]:
        """
        Extract structured vulnerabilities from execution history.
        
        Args:
            execution_history: List of command execution results
            
        Returns:
            List of structured Vulnerability objects
        """
        vulnerabilities = []
        
        for result in execution_history:
            for vuln_line in result.vulnerabilities_found:
                vuln = self._parse_vulnerability_line(vuln_line)
                if vuln:
                    vulnerabilities.append(vuln)
        
        # Deduplicate by CVE/name
        seen = set()
        unique_vulns = []
        for vuln in vulnerabilities:
            key = vuln.cve_id if vuln.cve_id else vuln.name
            if key not in seen:
                seen.add(key)
                unique_vulns.append(vuln)
        
        logger.info(f"Extracted {len(unique_vulns)} unique vulnerabilities from {len(execution_history)} executions")
        return unique_vulns

    def _parse_vulnerability_line(self, line: str) -> Optional[Vulnerability]:
        """Parse a single vulnerability indicator line."""
        # CVE-2011-2523 - vsFTPd backdoor
        if "CVE-2011-2523" in line or "vsftpd" in line.lower():
            return Vulnerability(
                name="vsFTPd 2.3.4 Backdoor",
                description="Backdoor in vsFTPd 2.3.4 allowing remote code execution",
                severity=VulnerabilitySeverity.CRITICAL,
                cvss_score=10.0,
                cve_id="CVE-2011-2523",
                service="FTP",
                port=21,
                exploit_method="Backdoor trigger",
            )
        
        # CVE-2010-2075 - UnrealIRCd backdoor
        elif "CVE-2010-2075" in line or "unrealircd" in line.lower():
            return Vulnerability(
                name="UnrealIRCd Backdoor",
                description="Trojaned UnrealIRCd with backdoor command execution",
                severity=VulnerabilitySeverity.HIGH,
                cvss_score=7.5,
                cve_id="CVE-2010-2075",
                service="IRC",
                port=6667,
                exploit_method="Backdoor command",
            )
        
        # CVE-2007-2447 - Samba usermap_script
        elif "CVE-2007-2447" in line or "samba" in line.lower():
            return Vulnerability(
                name="Samba usermap_script RCE",
                description="Command injection in Samba usermap_script",
                severity=VulnerabilitySeverity.MEDIUM,
                cvss_score=6.0,
                cve_id="CVE-2007-2447",
                service="SMB",
                port=445,
                exploit_method="Command injection",
            )
        
        # SQL Injection
        elif "SQL" in line.upper() and "INJECTION" in line.upper():
            return Vulnerability(
                name="SQL Injection",
                description="SQL injection vulnerability in web application",
                severity=VulnerabilitySeverity.HIGH,
                cvss_score=8.5,
                cve_id=None,
                service="HTTP",
                port=80,
                exploit_method="SQL injection",
            )
        
        return None


class PentestModule:
    """
    Complete Pentest Module (Stage 1) coordinating all agents.
    
    Workflow:
    1. Planner creates initial attack plan
    2. For each task:
       a. Instructor provides guidance
       b. Executor executes command
       c. Summarizer condenses output
       d. Planner updates plan
    3. After success: Apply counterfactual reasoning
    4. Extractor parses final vulnerabilities
    """

    def __init__(self, config: PentestAIConfig, llm_clients: Optional[dict] = None):
        self.config = config
        
        # Initialize agents with LLM clients
        if llm_clients:
            self.planner = PlannerAgent(config, llm_clients.get("planner"))
            self.executor = ExecutorAgent(config, llm_clients.get("executor"))
            self.instructor = InstructorAgent(config, llm_clients.get("utility"))
            self.summarizer = SummarizerAgent(config, llm_clients.get("utility"))
            self.extractor = ExtractorAgent(config, llm_clients.get("utility"))
        else:
            self.planner = PlannerAgent(config)
            self.executor = ExecutorAgent(config)
            self.instructor = InstructorAgent(config)
            self.summarizer = SummarizerAgent(config)
            self.extractor = ExtractorAgent(config)
        
        self.execution_history: list[ExecutionResult] = []
        self.counterfactual_round = 0

    def run_pentest(self, target: str) -> PentestResult:
        """
        Run complete penetration test on target.
        
        Args:
            target: Target system IP/hostname
            
        Returns:
            Complete pentest results
        """
        logger.info(f"Starting penetration test on target: {target}")
        start_time = datetime.now()
        
        # Create initial attack plan
        attack_plan = self.planner.create_initial_plan(target)
        
        # Execute tasks
        iteration = 0
        while iteration < self.config.max_iterations:
            iteration += 1
            
            # Get next task
            task = self.planner.get_next_task()
            if not task:
                logger.info("No more tasks to execute")
                break
            
            # Get guidance from Instructor
            guidance = self.instructor.get_guidance(task)
            
            # Execute task
            result = self.executor.execute_task(task, guidance)
            self.execution_history.append(result)
            
            # Summarize output
            summary = self.summarizer.summarize(result.output)
            result.summary = summary
            
            # Update task status
            status = TaskStatus.COMPLETED if result.success else TaskStatus.FAILED
            self.planner.update_task_status(task.id, status, summary)
            
            # Apply counterfactual reasoning if vulnerabilities found
            if result.vulnerabilities_found and self.counterfactual_round < self.config.counterfactual_rounds:
                self.counterfactual_round += 1
                self.planner.apply_counterfactual_reasoning(result.vulnerabilities_found)
                logger.info(f"Counterfactual reasoning round {self.counterfactual_round}")
        
        # Extract vulnerabilities
        vulnerabilities = self.extractor.extract_vulnerabilities(self.execution_history)
        
        # Create result
        end_time = datetime.now()
        result = PentestResult(
            target=target,
            start_time=start_time,
            end_time=end_time,
            vulnerabilities=vulnerabilities,
            attack_plan=attack_plan,
            execution_history=self.execution_history,
            statistics={
                "total_iterations": iteration,
                "tasks_executed": len(self.execution_history),
                "vulnerabilities_found": len(vulnerabilities),
                "counterfactual_rounds": self.counterfactual_round,
                "duration_seconds": (end_time - start_time).total_seconds(),
            }
        )
        
        logger.info(f"Penetration test completed. Found {len(vulnerabilities)} vulnerabilities in {iteration} iterations")
        return result
