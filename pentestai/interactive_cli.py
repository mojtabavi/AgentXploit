"""
Interactive CLI for PentestAI

Provides a user-friendly menu-based interface for running assessments.
"""

import os
import sys
from typing import Optional
from pathlib import Path

from pentestai import PentestAIController, PentestAIConfig
from pentestai.models.data import Vulnerability, VulnerabilitySeverity


class Colors:
    """ANSI color codes for terminal output"""
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'


def print_banner():
    """Print PentestAI banner"""
    banner = f"""
{Colors.CYAN}{Colors.BOLD}
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                               ‚ïë
‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ïë
‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê ‚ïë
‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïë   ‚ïë
‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ïë
‚ïë   ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ïë
‚ïë   ‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù   ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù   ‚ïö‚ïê‚ïù   ‚ïë
‚ïë                                                               ‚ïë
‚ïë        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó    Interactive Assessment Tool              ‚ïë    
‚ïë       ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë                                             ‚ïë
‚ïë       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë    AI-Powered Penetration Testing           ‚ïë
‚ïë       ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë    & Optimal Remediation Planning           ‚ïë
‚ïë       ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë                                             ‚ïë
‚ïë       ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù    v1.0.0                                   ‚ïë
‚ïë                                                               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
{Colors.END}
    """
    print(banner)


def print_separator(char="=", length=65):
    """Print a separator line"""
    print(f"{Colors.CYAN}{char * length}{Colors.END}")


def print_header(text: str):
    """Print a section header"""
    print(f"\n{Colors.BOLD}{Colors.BLUE}{'='*65}")
    print(f"  {text}")
    print(f"{'='*65}{Colors.END}\n")


def print_success(text: str):
    """Print success message"""
    print(f"{Colors.GREEN}‚úì {text}{Colors.END}")


def print_warning(text: str):
    """Print warning message"""
    print(f"{Colors.YELLOW}‚ö† {text}{Colors.END}")


def print_error(text: str):
    """Print error message"""
    print(f"{Colors.RED}‚úó {text}{Colors.END}")


def print_info(text: str):
    """Print info message"""
    print(f"{Colors.CYAN}‚Ñπ {text}{Colors.END}")


def get_input(prompt: str, default: Optional[str] = None) -> str:
    """Get user input with optional default value"""
    if default:
        full_prompt = f"{Colors.BOLD}{prompt} [{default}]: {Colors.END}"
    else:
        full_prompt = f"{Colors.BOLD}{prompt}: {Colors.END}"
    
    value = input(full_prompt).strip()
    return value if value else (default or "")


def get_yes_no(prompt: str, default: bool = True) -> bool:
    """Get yes/no input from user"""
    default_str = "Y/n" if default else "y/N"
    full_prompt = f"{Colors.BOLD}{prompt} [{default_str}]: {Colors.END}"
    
    while True:
        response = input(full_prompt).strip().lower()
        
        if not response:
            return default
        
        if response in ['y', 'yes']:
            return True
        elif response in ['n', 'no']:
            return False
        else:
            print_error("Please enter 'y' or 'n'")


def show_main_menu() -> int:
    """Display main menu and get user choice"""
    print_header("MAIN MENU")
    
    print(f"{Colors.BOLD}1.{Colors.END} Full Assessment (Pentest + Remediation)")
    print(f"{Colors.BOLD}2.{Colors.END} Pentest Only (Vulnerability Discovery)")
    print(f"{Colors.BOLD}3.{Colors.END} Remediation Only (Plan Fixes)")
    print(f"{Colors.BOLD}4.{Colors.END} Configuration Settings")
    print(f"{Colors.BOLD}5.{Colors.END} View Previous Results")
    print(f"{Colors.BOLD}6.{Colors.END} Help & Documentation")
    print(f"{Colors.BOLD}0.{Colors.END} Exit")
    
    print()
    
    while True:
        try:
            choice = int(get_input("Select option", "1"))
            if 0 <= choice <= 6:
                return choice
            else:
                print_error("Please enter a number between 0 and 6")
        except ValueError:
            print_error("Please enter a valid number")


def configure_assessment() -> PentestAIConfig:
    """Interactive configuration wizard"""
    print_header("ASSESSMENT CONFIGURATION")
    
    # Target configuration
    print_info("Target Configuration")
    target = get_input("Target IP address or hostname", "192.168.1.100")
    
    # OpenAI configuration
    print()
    print_info("OpenAI Configuration")
    api_key = os.getenv("OPENAI_API_KEY")
    
    if api_key:
        print_success(f"API key found in environment: {api_key[:10]}...{api_key[-4:]}")
        use_env_key = get_yes_no("Use this API key?", True)
        if not use_env_key:
            api_key = get_input("Enter OpenAI API key")
    else:
        print_warning("No OPENAI_API_KEY environment variable found")
        has_key = get_yes_no("Do you have an OpenAI API key?", False)
        if has_key:
            api_key = get_input("Enter OpenAI API key")
        else:
            print_info("Will use mock LLM (simulated responses)")
            api_key = None
    
    # Assessment parameters
    print()
    print_info("Assessment Parameters")
    max_iterations = int(get_input("Max pentest iterations", "20"))
    counterfactual_rounds = int(get_input("Counterfactual reasoning rounds", "2"))
    
    # Remediation parameters
    print()
    print_info("Remediation Parameters")
    remediation_budget = float(get_input("Remediation budget (cost units)", "50.0"))
    
    # Model selection
    print()
    print_info("LLM Model Selection")
    print("Available models: gpt-4, gpt-4-turbo, gpt-3.5-turbo")
    planner_model = get_input("Planner model", "gpt-4")
    
    use_same = get_yes_no("Use same model for all agents?", True)
    if use_same:
        executor_model = advisor_model = evaluator_model = planner_model
        utility_model = "gpt-3.5-turbo"
    else:
        executor_model = get_input("Executor model", "gpt-4")
        advisor_model = get_input("Advisor model", "gpt-4")
        evaluator_model = get_input("Evaluator model", "gpt-4")
        utility_model = get_input("Utility model (summarizer/extractor)", "gpt-3.5-turbo")
    
    # Safety
    print()
    print_info("Safety Settings")
    print_warning("IMPORTANT: Sandbox mode simulates attacks without real execution")
    sandbox_mode = get_yes_no("Enable sandbox mode (RECOMMENDED)?", True)
    
    # Output
    print()
    print_info("Output Settings")
    output_dir = get_input("Output directory", "./pentestai_results")
    
    # Create configuration
    config = PentestAIConfig(
        target=target,
        max_iterations=max_iterations,
        counterfactual_rounds=counterfactual_rounds,
        remediation_budget=remediation_budget,
        openai_api_key=api_key,
        planner_model=planner_model,
        executor_model=executor_model,
        advisor_model=advisor_model,
        evaluator_model=evaluator_model,
        utility_model=utility_model,
        sandbox_mode=sandbox_mode,
        output_directory=output_dir,
    )
    
    # Confirmation
    print()
    print_separator()
    print_info("Configuration Summary:")
    print(f"  Target: {Colors.BOLD}{target}{Colors.END}")
    print(f"  Max Iterations: {max_iterations}")
    print(f"  Budget: ${remediation_budget}")
    print(f"  Planner Model: {planner_model}")
    print(f"  Sandbox Mode: {Colors.GREEN if sandbox_mode else Colors.RED}{sandbox_mode}{Colors.END}")
    print(f"  LLM Mode: {Colors.GREEN}OpenAI{Colors.END}" if api_key else f"{Colors.YELLOW}Mock (no API key){Colors.END}")
    print_separator()
    
    if get_yes_no("\nProceed with this configuration?", True):
        return config
    else:
        print_info("Configuration cancelled. Returning to main menu.")
        return None


def display_vulnerabilities(vulnerabilities: list):
    """Display discovered vulnerabilities in a formatted table"""
    if not vulnerabilities:
        print_warning("No vulnerabilities found")
        return
    
    print_header(f"DISCOVERED VULNERABILITIES ({len(vulnerabilities)})")
    
    # Group by severity
    by_severity = {}
    for vuln in vulnerabilities:
        severity = vuln.severity.name
        if severity not in by_severity:
            by_severity[severity] = []
        by_severity[severity].append(vuln)
    
    # Display by severity (highest first)
    severity_order = ["CRITICAL", "HIGH", "MEDIUM", "LOW", "INFO"]
    severity_colors = {
        "CRITICAL": Colors.RED,
        "HIGH": Colors.YELLOW,
        "MEDIUM": Colors.CYAN,
        "LOW": Colors.GREEN,
        "INFO": Colors.BLUE,
    }
    
    for severity in severity_order:
        if severity in by_severity:
            vulns = by_severity[severity]
            color = severity_colors.get(severity, "")
            
            print(f"\n{color}{Colors.BOLD}[{severity}] {len(vulns)} vulnerabilities{Colors.END}")
            print_separator("-")
            
            for i, vuln in enumerate(vulns, 1):
                print(f"{color}{i}. {vuln.name}{Colors.END}")
                print(f"   CVE: {vuln.cve_id or 'N/A'}")
                print(f"   CVSS: {vuln.cvss_score}/10.0")
                print(f"   Service: {vuln.service} (Port {vuln.port})")
                print(f"   Description: {vuln.description[:80]}...")
                print()


def display_remediation_strategies(strategies: list):
    """Display selected remediation strategies"""
    if not strategies:
        print_warning("No remediation strategies selected")
        return
    
    print_header(f"RECOMMENDED REMEDIATION STRATEGIES ({len(strategies)})")
    
    for i, strategy in enumerate(strategies, 1):
        print(f"\n{Colors.BOLD}{i}. {strategy.description}{Colors.END}")
        print(f"   Type: {strategy.type.name}")
        print(f"   Effectiveness: {Colors.GREEN}{strategy.value_score:.1f}/10{Colors.END}")
        print(f"   Cost: {Colors.YELLOW}{strategy.cost_score:.1f}/10{Colors.END}")
        print(f"   Time: {strategy.estimated_time} minutes")
        print(f"   Risk Level: {strategy.risk_level}")
        
        if strategy.commands and len(strategy.commands) > 0:
            print(f"   {Colors.CYAN}Commands:{Colors.END}")
            for cmd in strategy.commands[:3]:  # Show first 3
                print(f"     $ {cmd}")
            if len(strategy.commands) > 3:
                print(f"     ... and {len(strategy.commands) - 3} more")


def run_full_assessment(config: PentestAIConfig):
    """Run full two-stage assessment with progress display"""
    print_header("RUNNING FULL ASSESSMENT")
    
    print_info(f"Target: {config.target}")
    print_info(f"Sandbox Mode: {config.sandbox_mode}")
    print_info(f"LLM Mode: {'OpenAI' if config.openai_api_key else 'Mock'}")
    
    if not config.sandbox_mode:
        print_warning("\n‚ö†Ô∏è  DANGER: Sandbox mode is DISABLED!")
        print_warning("Real commands will be executed on the target system!")
        if not get_yes_no("Are you SURE you want to continue?", False):
            print_info("Assessment cancelled for safety")
            return
    
    print()
    print_separator()
    
    try:
        # Initialize controller
        print_info("Initializing PentestAI controller...")
        controller = PentestAIController(config)
        print_success("Controller initialized\n")
        
        # Stage 1: Pentest
        print(f"{Colors.BOLD}{Colors.BLUE}STAGE 1: VULNERABILITY DISCOVERY{Colors.END}")
        print_separator("-")
        print_info("Running penetration testing module...")
        print_info("This may take several minutes depending on iterations and target...")
        print()
        
        pentest_result = controller.run_pentest_only()
        
        print_success(f"Pentest complete!")
        print_info(f"Vulnerabilities discovered: {len(pentest_result.vulnerabilities)}")
        print_info(f"Tasks executed: {len(pentest_result.execution_history)}")
        print()
        
        # Display vulnerabilities
        display_vulnerabilities(pentest_result.vulnerabilities)
        
        input(f"\n{Colors.BOLD}Press Enter to continue to remediation planning...{Colors.END}")
        
        # Stage 2: Remediation
        print(f"\n{Colors.BOLD}{Colors.BLUE}STAGE 2: REMEDIATION PLANNING{Colors.END}")
        print_separator("-")
        print_info("Running remediation module...")
        print_info("Generating and optimizing remediation strategies...")
        print()
        
        remediation_result = controller.run_remediation_only(pentest_result.vulnerabilities)
        
        print_success(f"Remediation planning complete!")
        print_info(f"Strategies generated: {len(remediation_result.all_strategies)}")
        print_info(f"Optimal strategies selected: {len(remediation_result.selected_strategies)}")
        print_info(f"Total value: {remediation_result.total_value:.2f}")
        print_info(f"Total cost: {remediation_result.total_cost:.2f}/{config.remediation_budget}")
        print_info(f"Budget utilization: {remediation_result.budget_used:.1f}%")
        print()
        
        # Display strategies
        display_remediation_strategies(remediation_result.selected_strategies)
        
        # Statistics
        print_header("ASSESSMENT STATISTICS")
        stats = controller.get_statistics(pentest_result, remediation_result)
        
        print(f"Total Vulnerabilities: {Colors.BOLD}{stats['total_vulnerabilities']}{Colors.END}")
        print(f"Severity Distribution:")
        for severity, count in stats['severity_distribution'].items():
            color = {
                'CRITICAL': Colors.RED,
                'HIGH': Colors.YELLOW,
                'MEDIUM': Colors.CYAN,
                'LOW': Colors.GREEN,
                'INFO': Colors.BLUE,
            }.get(severity, '')
            print(f"  {color}{severity}: {count}{Colors.END}")
        
        print(f"\nAverage CVSS Score: {Colors.BOLD}{stats['average_cvss']:.2f}{Colors.END}")
        print(f"Total Strategies Generated: {stats['total_strategies']}")
        print(f"Selected Strategies: {stats['selected_strategies']}")
        print(f"Budget Efficiency: {stats['budget_efficiency']:.1f}%")
        
        # Save results
        print()
        if get_yes_no("Save results to disk?", True):
            print_info(f"Results saved to: {config.output_directory}")
            print_success("Assessment complete!")
        
    except KeyboardInterrupt:
        print_error("\n\nAssessment interrupted by user")
    except Exception as e:
        print_error(f"\nError during assessment: {str(e)}")
        import traceback
        traceback.print_exc()


def run_pentest_only(config: PentestAIConfig):
    """Run only vulnerability discovery"""
    print_header("RUNNING VULNERABILITY DISCOVERY")
    
    try:
        controller = PentestAIController(config)
        print_info("Running penetration testing...")
        
        pentest_result = controller.run_pentest_only()
        
        print_success("Pentest complete!")
        display_vulnerabilities(pentest_result.vulnerabilities)
        
    except Exception as e:
        print_error(f"Error: {str(e)}")


def show_help():
    """Display help and documentation"""
    print_header("HELP & DOCUMENTATION")
    
    print(f"{Colors.BOLD}About PentestAI:{Colors.END}")
    print("  PentestAI is a two-stage AI-powered framework for automated")
    print("  penetration testing and optimal remediation planning.")
    print()
    
    print(f"{Colors.BOLD}Two-Stage Architecture:{Colors.END}")
    print(f"  {Colors.CYAN}Stage 1:{Colors.END} Vulnerability Discovery")
    print("    - 6 specialized agents (Planner, Executor, Instructor, etc.)")
    print("    - Counterfactual reasoning for comprehensive coverage")
    print("    - RAG-based knowledge system")
    print()
    print(f"  {Colors.CYAN}Stage 2:{Colors.END} Remediation Planning")
    print("    - 4 specialized agents (Estimator, Advisor, Evaluator, Optimizer)")
    print("    - Group Knapsack optimization")
    print("    - Budget-constrained strategy selection")
    print()
    
    print(f"{Colors.BOLD}Safety:{Colors.END}")
    print(f"  {Colors.GREEN}‚úì{Colors.END} Always use sandbox mode for testing")
    print(f"  {Colors.GREEN}‚úì{Colors.END} Real mode requires explicit authorization")
    print(f"  {Colors.GREEN}‚úì{Colors.END} Framework is for research and education")
    print()
    
    print(f"{Colors.BOLD}Documentation:{Colors.END}")
    print("  - README.md              : Quick start guide")
    print("  - PENTESTAI_README.md    : Complete documentation")
    print("  - SETUP_COMPLETE.md      : Setup guide")
    print("  - quickstart.py          : Usage examples")
    print()
    
    print(f"{Colors.BOLD}OpenAI API Key:{Colors.END}")
    print("  Set environment variable:")
    print(f"  {Colors.CYAN}  export OPENAI_API_KEY='sk-...'{Colors.END}")
    print()


def main():
    """Main interactive CLI loop"""
    print_banner()
    
    # Check for API key
    if not os.getenv("OPENAI_API_KEY"):
        print_warning("No OPENAI_API_KEY environment variable found")
        print_info("Framework will use mock LLM (simulated responses)")
        print_info("Set OPENAI_API_KEY for real AI-powered assessment\n")
    else:
        print_success("OpenAI API key detected\n")
    
    config = None
    
    while True:
        try:
            choice = show_main_menu()
            
            if choice == 0:
                print_info("\nThank you for using PentestAI!")
                print_success("Stay safe! üîí\n")
                break
            
            elif choice == 1:
                # Full assessment
                if not config:
                    config = configure_assessment()
                if config:
                    run_full_assessment(config)
                    config = None  # Reset for next run
                input(f"\n{Colors.BOLD}Press Enter to return to main menu...{Colors.END}")
            
            elif choice == 2:
                # Pentest only
                if not config:
                    config = configure_assessment()
                if config:
                    run_pentest_only(config)
                    config = None
                input(f"\n{Colors.BOLD}Press Enter to return to main menu...{Colors.END}")
            
            elif choice == 3:
                # Remediation only
                print_info("Remediation-only mode requires existing vulnerability data")
                print_info("Run full assessment or pentest first")
                input(f"\n{Colors.BOLD}Press Enter to continue...{Colors.END}")
            
            elif choice == 4:
                # Configuration
                config = configure_assessment()
                if config:
                    print_success("Configuration saved for next assessment")
                input(f"\n{Colors.BOLD}Press Enter to continue...{Colors.END}")
            
            elif choice == 5:
                # View results
                print_info("Results viewing not implemented yet")
                print_info("Check the output directory for saved results")
                input(f"\n{Colors.BOLD}Press Enter to continue...{Colors.END}")
            
            elif choice == 6:
                # Help
                show_help()
                input(f"\n{Colors.BOLD}Press Enter to continue...{Colors.END}")
        
        except KeyboardInterrupt:
            print()
            if get_yes_no("\nReally exit?", True):
                print_info("Goodbye!")
                break
        except Exception as e:
            print_error(f"\nUnexpected error: {str(e)}")
            import traceback
            traceback.print_exc()
            input(f"\n{Colors.BOLD}Press Enter to continue...{Colors.END}")


if __name__ == "__main__":
    main()
